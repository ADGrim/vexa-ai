import { useState, useEffect, useRef } from "react";
import { Card, CardContent } from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import { Textarea } from "@/components/ui/textarea";

const OPENAI_API_KEY = "YOUR_OPENAI_API_KEY"; // Replace with your actual API key
const SERP_API_KEY = "YOUR_SERPAPI_KEY"; // Replace with your web search API key

export default function VexaAI() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState("");
  const [memory, setMemory] = useState([]);
  const [tasks, setTasks] = useState([]);
  const [backgroundActive, setBackgroundActive] = useState(false);
  const [voiceRecognitionActive, setVoiceRecognitionActive] = useState(false);
  const canvasRef = useRef(null);

  useEffect(() => {
    loadTasks();
  }, []);

  useEffect(() => {
    if (voiceRecognitionActive) {
      startVoiceRecognition();
    }
  }, [voiceRecognitionActive]);

  const fetchAIResponse = async (userInput) => {
    const fullContext = [...memory, { role: "user", content: userInput }];
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: "gpt-4",
        messages: fullContext,
      }),
    });
    const data = await response.json();
    const aiResponse = data.choices[0].message.content;
    setMemory([...fullContext, { role: "assistant", content: aiResponse }]);
    startStreamingTTS(aiResponse);
    return aiResponse;
  };

  const performWebSearch = async (query) => {
    const response = await fetch(
      `https://serpapi.com/search.json?q=${encodeURIComponent(query)}&api_key=${SERP_API_KEY}`
    );
    const data = await response.json();
    return data.organic_results ? data.organic_results.slice(0, 3).map((r) => r.snippet).join("\n") : "No relevant results found.";
  };

  const sendMessage = async () => {
    if (!input.trim()) return;
    const newMessage = { text: input, sender: "user" };
    setMessages([...messages, newMessage]);
    setInput("");

    let aiResponse = "";
    if (input.toLowerCase().includes("search for")) {
      const query = input.replace("search for", "").trim();
      aiResponse = await performWebSearch(query);
    } else {
      aiResponse = await fetchAIResponse(input);
    }

    setMessages((prev) => [...prev, { text: aiResponse, sender: "ai" }]);
  };

  const startStreamingTTS = async (text) => {
    const response = await fetch("https://api.openai.com/v1/audio/speech", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "tts-1-hd",
        input: text,
        voice: "nova", // or 'shimmer' / 'echo' if preferred
        response_format: "mp3",
      }),
    });

    const blob = await response.blob();
    const audioUrl = URL.createObjectURL(blob);
    const audio = new Audio(audioUrl);
    audio.play();
    visualizeAudio(audio);
  };

  const visualizeAudio = (audio) => {
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const source = audioCtx.createMediaElementSource(audio);
    const analyser = audioCtx.createAnalyser();
    source.connect(analyser);
    analyser.connect(audioCtx.destination);
    analyser.fftSize = 256;

    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    const canvas = canvasRef.current;
    const ctx = canvas.getContext("2d");

    function draw() {
      requestAnimationFrame(draw);
      analyser.getByteFrequencyData(dataArray);

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      const barWidth = (canvas.width / bufferLength) * 2.5;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        const barHeight = dataArray[i];
        ctx.fillStyle = "rgb(50,50," + (barHeight + 100) + ")";
        ctx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight / 2);
        x += barWidth + 1;
      }
    }
    draw();
  };

  const startVoiceRecognition = () => {
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = true;
    recognition.interimResults = false;
    recognition.lang = "en-US";

    recognition.onresult = async (event) => {
      const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase();
      if (transcript.includes("vexa")) {
        const aiResponse = await fetchAIResponse("Hey Vexa");
        setMessages((prev) => [...prev, { text: aiResponse, sender: "ai" }]);
      }
    };
    recognition.start();
  };

  const addTask = (task) => {
    const newTasks = [...tasks, task];
    setTasks(newTasks);
    localStorage.setItem("tasks", JSON.stringify(newTasks));
  };

  const loadTasks = () => {
    const savedTasks = JSON.parse(localStorage.getItem("tasks")) || [];
    setTasks(savedTasks);
  };

  return (
    <div className="flex flex-col h-screen p-4">
      <Card className="flex-1 overflow-y-auto p-4">
        <CardContent>
          {messages.map((msg, index) => (
            <div key={index} className={msg.sender === "user" ? "text-right" : "text-left"}>
              <p className="p-2 bg-gray-200 rounded-lg inline-block m-1">{msg.text}</p>
            </div>
          ))}
        </CardContent>
      </Card>
      <canvas ref={canvasRef} width="600" height="100" className="mt-4 border" />
      <div className="flex gap-2 mt-4">
        <Textarea
          className="flex-1"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Type a message or task..."
        />
        <Button onClick={sendMessage}>Send</Button>
      </div>
      <div className="flex justify-center gap-4 mt-4">
        <Button onClick={() => setBackgroundActive(!backgroundActive)}>
          {backgroundActive ? "Disable Background Chat" : "Enable Background Chat"}
        </Button>
        <Button onClick={() => setVoiceRecognitionActive(!voiceRecognitionActive)}>
          {voiceRecognitionActive ? "Disable Voice Activation" : "Enable Voice Activation"}
        </Button>
      </div>
      <div className="flex flex-col mt-4">
        <h2 className="text-lg font-semibold">Tasks</h2>
        <ul>
          {tasks.map((task, index) => (
            <li key={index} className="p-2 bg-gray-100 rounded mt-1">
              {task}
            </li>
          ))}
        </ul>
        <Textarea
          className="mt-2"
          placeholder="Add a new task..."
          onKeyDown={(e) => {
            if (e.key === "Enter") {
              e.preventDefault();
              addTask(e.target.value);
              e.target.value = "";
            }
          }}
        />
      </div>
    </div>
  );
}
